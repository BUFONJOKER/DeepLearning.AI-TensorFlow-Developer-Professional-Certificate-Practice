{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fashion mnist dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168 133  16   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217 215 254 231 160  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201 201 201 209 218 224 164   0   0   0   0]\n",
      " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200 200 200 200 201 200 225  41   0   0   0]\n",
      " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252 248 235 207 203 203 222 140   0   0   0]\n",
      " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51  63 113 222 202 206 220 224   0   0   0]\n",
      " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71  49   0 219 206 214 210 250  38   0   0]\n",
      " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255 205   0 215 217 214 208 220  95   0   0]\n",
      " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13  70   0 189 216 212 206 212 156   0   0]\n",
      " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76  92  87 206 207 222 213 219 208   0   0]\n",
      " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250 252 239 201 212 225 215 193 113   0   0]\n",
      " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201 203 195 210 165   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204 212 197 218 107   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204 212 200 218  91   0   3   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204 205 205 218  77   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206 199 209 219  74   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208 198 207 221  72   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208 200 202 222  75   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206 205 198 221  80   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210 209 195 221  96   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209 210 194 217 105   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208 211 193 213 115   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207 212 195 210 118   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207 211 196 207 121   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207 210 197 207 124   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201 205 197 206 127   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240 243 214 224 162   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121 119 114 130  76   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "print(train_labels[1])\n",
    "print(train_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0], cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "\n",
    "train_images = train_images /  255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.00392157 0.         0.         0.         0.         0.16078431 0.7372549  0.40392157 0.21176471 0.18823529 0.16862745 0.34117647\n",
      "  0.65882353 0.52156863 0.0627451  0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00392157 0.         0.         0.         0.19215686 0.53333333 0.85882353 0.84705882 0.89411765 0.9254902  1.         1.         1.         1.\n",
      "  0.85098039 0.84313725 0.99607843 0.90588235 0.62745098 0.17647059 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.05490196 0.69019608 0.87058824 0.87843137 0.83137255 0.79607843 0.77647059 0.76862745 0.78431373 0.84313725 0.8        0.79215686\n",
      "  0.78823529 0.78823529 0.78823529 0.81960784 0.85490196 0.87843137 0.64313725 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.7372549  0.85882353 0.78431373 0.77647059 0.79215686 0.77647059 0.78039216 0.78039216 0.78823529 0.76862745 0.77647059 0.77647059\n",
      "  0.78431373 0.78431373 0.78431373 0.78431373 0.78823529 0.78431373 0.88235294 0.16078431 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2        0.85882353 0.78039216 0.79607843 0.79607843 0.83137255 0.93333333 0.97254902 0.98039216 0.96078431 0.97647059 0.96470588 0.96862745\n",
      "  0.98823529 0.97254902 0.92156863 0.81176471 0.79607843 0.79607843 0.87058824 0.54901961 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.45490196 0.88627451 0.80784314 0.8        0.81176471 0.8        0.39607843 0.29411765 0.18431373 0.28627451 0.18823529 0.19607843 0.17647059\n",
      "  0.2        0.24705882 0.44313725 0.87058824 0.79215686 0.80784314 0.8627451  0.87843137 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.78431373 0.87058824 0.81960784 0.79607843 0.84313725 0.78431373 0.         0.2745098  0.38431373 0.         0.40392157 0.23137255 0.26666667\n",
      "  0.27843137 0.19215686 0.         0.85882353 0.80784314 0.83921569 0.82352941 0.98039216 0.14901961 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.96862745 0.85490196 0.83137255 0.82352941 0.84313725 0.83921569 0.         0.99607843 0.95294118 0.54509804 1.         0.68235294 0.98431373\n",
      "  1.         0.80392157 0.         0.84313725 0.85098039 0.83921569 0.81568627 0.8627451  0.37254902 0.         0.        ]\n",
      " [0.         0.         0.         0.17647059 0.88627451 0.83921569 0.83921569 0.84313725 0.87843137 0.80392157 0.         0.16470588 0.1372549  0.23529412 0.0627451  0.06666667 0.04705882\n",
      "  0.05098039 0.2745098  0.         0.74117647 0.84705882 0.83137255 0.80784314 0.83137255 0.61176471 0.         0.        ]\n",
      " [0.         0.         0.         0.64313725 0.92156863 0.83921569 0.82745098 0.8627451  0.84705882 0.78823529 0.20392157 0.27843137 0.34901961 0.36862745 0.3254902  0.30588235 0.2745098\n",
      "  0.29803922 0.36078431 0.34117647 0.80784314 0.81176471 0.87058824 0.83529412 0.85882353 0.81568627 0.         0.        ]\n",
      " [0.         0.         0.         0.41568627 0.73333333 0.8745098  0.92941176 0.97254902 0.82745098 0.77647059 0.98823529 0.98039216 0.97254902 0.96078431 0.97254902 0.98823529 0.99215686\n",
      "  0.98039216 0.98823529 0.9372549  0.78823529 0.83137255 0.88235294 0.84313725 0.75686275 0.44313725 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.06666667 0.21176471 0.62352941 0.87058824 0.75686275 0.81568627 0.75294118 0.77254902 0.78431373 0.78431373 0.78431373 0.78431373\n",
      "  0.78823529 0.79607843 0.76470588 0.82352941 0.64705882 0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.18431373 0.88235294 0.75294118 0.83921569 0.79607843 0.80784314 0.8        0.8        0.80392157 0.80784314\n",
      "  0.8        0.83137255 0.77254902 0.85490196 0.41960784 0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.02352941 0.         0.18039216 0.83137255 0.76470588 0.83137255 0.79215686 0.80784314 0.80392157 0.8        0.80392157 0.80784314\n",
      "  0.8        0.83137255 0.78431373 0.85490196 0.35686275 0.         0.01176471 0.00392157 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.04313725 0.77254902 0.78039216 0.80392157 0.79215686 0.80392157 0.80784314 0.8        0.80392157 0.81176471\n",
      "  0.8        0.80392157 0.80392157 0.85490196 0.30196078 0.         0.01960784 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01176471 0.         0.00784314 0.74901961 0.77647059 0.78823529 0.80392157 0.80784314 0.80392157 0.80392157 0.80784314 0.81960784\n",
      "  0.80784314 0.78039216 0.81960784 0.85882353 0.29019608 0.         0.01960784 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00784314 0.         0.         0.7372549  0.77254902 0.78431373 0.81176471 0.81176471 0.8        0.81176471 0.81176471 0.82352941\n",
      "  0.81568627 0.77647059 0.81176471 0.86666667 0.28235294 0.         0.01568627 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00784314 0.         0.         0.84313725 0.77647059 0.79607843 0.80784314 0.81568627 0.80392157 0.81176471 0.81176471 0.82352941\n",
      "  0.81568627 0.78431373 0.79215686 0.87058824 0.29411765 0.         0.01568627 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.83137255 0.77647059 0.81960784 0.80784314 0.81960784 0.80784314 0.81568627 0.81176471 0.82745098\n",
      "  0.80784314 0.80392157 0.77647059 0.86666667 0.31372549 0.         0.01176471 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.8        0.78823529 0.80392157 0.81568627 0.81176471 0.80392157 0.82745098 0.80392157 0.82352941\n",
      "  0.82352941 0.81960784 0.76470588 0.86666667 0.37647059 0.         0.01176471 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.79215686 0.78823529 0.80392157 0.81960784 0.81176471 0.80392157 0.83529412 0.80784314 0.82352941\n",
      "  0.81960784 0.82352941 0.76078431 0.85098039 0.41176471 0.         0.00784314 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.8        0.8        0.80392157 0.81568627 0.81176471 0.80392157 0.84313725 0.81176471 0.82352941\n",
      "  0.81568627 0.82745098 0.75686275 0.83529412 0.45098039 0.         0.00784314 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.8        0.81176471 0.81176471 0.81568627 0.80784314 0.80784314 0.84313725 0.82352941 0.82352941\n",
      "  0.81176471 0.83137255 0.76470588 0.82352941 0.4627451  0.         0.00784314 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.77647059 0.81568627 0.81568627 0.81568627 0.8        0.81176471 0.83137255 0.83137255 0.82352941\n",
      "  0.81176471 0.82745098 0.76862745 0.81176471 0.4745098  0.         0.00392157 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.77647059 0.82352941 0.81176471 0.81568627 0.80784314 0.81960784 0.83529412 0.83137255 0.82745098\n",
      "  0.81176471 0.82352941 0.77254902 0.81176471 0.48627451 0.         0.00392157 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.6745098  0.82352941 0.79607843 0.78823529 0.78039216 0.8        0.81176471 0.80392157 0.8\n",
      "  0.78823529 0.80392157 0.77254902 0.80784314 0.49803922 0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.7372549  0.86666667 0.83921569 0.91764706 0.9254902  0.93333333 0.95686275 0.95686275 0.95686275\n",
      "  0.94117647 0.95294118 0.83921569 0.87843137 0.63529412 0.         0.00784314 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157 0.         0.         0.54509804 0.57254902 0.50980392 0.52941176 0.52941176 0.5372549  0.49019608 0.48627451 0.49019608\n",
      "  0.4745098  0.46666667 0.44705882 0.50980392 0.29803922 0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=200)\n",
    "\n",
    "print(train_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abdul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# building the classification model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\abdul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\abdul\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4978 - accuracy: 0.8251\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3733 - accuracy: 0.8652\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3357 - accuracy: 0.8769\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3147 - accuracy: 0.8838\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2949 - accuracy: 0.8921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25748a9ffd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35359466075897217, 0.8759999871253967]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[2.3763803e-06 4.1612624e-09 3.9035289e-08 1.7776457e-09 2.3713483e-07 1.9897219e-02 6.7344850e-08 2.1755170e-02 6.0086877e-05 9.5828474e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.4691 - accuracy: 0.8318\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3561 - accuracy: 0.8697\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3207 - accuracy: 0.8823\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2967 - accuracy: 0.8904\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2786 - accuracy: 0.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2574f043750>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 22s 10ms/step - loss: 0.4714 - accuracy: 0.8321\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3617 - accuracy: 0.8673\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3218 - accuracy: 0.8822\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2977 - accuracy: 0.8890\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2789 - accuracy: 0.8963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25770950990>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 21s 10ms/step - loss: 0.4690 - accuracy: 0.8301\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3549 - accuracy: 0.8683\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3193 - accuracy: 0.8809\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2984 - accuracy: 0.8885\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2791 - accuracy: 0.8944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x257714f5350>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4673 - accuracy: 0.8298\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3542 - accuracy: 0.8699\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3227 - accuracy: 0.8801\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2972 - accuracy: 0.8880\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2781 - accuracy: 0.8964\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2638 - accuracy: 0.9001\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2510 - accuracy: 0.9048\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2406 - accuracy: 0.9085\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2288 - accuracy: 0.9133\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2206 - accuracy: 0.9166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2577183f490>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4701 - accuracy: 0.8301\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3556 - accuracy: 0.8690\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3223 - accuracy: 0.8821\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2994 - accuracy: 0.8882\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2806 - accuracy: 0.8950\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2650 - accuracy: 0.8998\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2515 - accuracy: 0.9042\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2406 - accuracy: 0.9090\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2286 - accuracy: 0.9130\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2213 - accuracy: 0.9154\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2125 - accuracy: 0.9194\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2049 - accuracy: 0.9211\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1957 - accuracy: 0.9249\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1891 - accuracy: 0.9285\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.1795 - accuracy: 0.9313\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1762 - accuracy: 0.9316\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1705 - accuracy: 0.9330\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1649 - accuracy: 0.9365\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1610 - accuracy: 0.9371\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1564 - accuracy: 0.9401\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1513 - accuracy: 0.9421\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1454 - accuracy: 0.9434\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1450 - accuracy: 0.9446\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1375 - accuracy: 0.9464\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1359 - accuracy: 0.9474\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1354 - accuracy: 0.9489\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1325 - accuracy: 0.9491\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1275 - accuracy: 0.9510\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1237 - accuracy: 0.9520\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1222 - accuracy: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2577231b750>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3461254835128784, 0.8762000203132629]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "[1.12166913e-06 4.53652007e-07 1.03171274e-07 1.45205237e-09 2.39663649e-07 3.78521363e-04 1.17408092e-06 3.45700011e-02 2.30302987e-07 9.65048194e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        if (logs.get('loss')<0.4):\n",
    "            \n",
    "            print(\" loss reached 0.4\")\n",
    "            \n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4733 - accuracy: 0.8322\n",
      "Epoch 2/5\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.8699loss reached 0.4\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3556 - accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25772dbd710>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, callbacks=[callbacks], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
